{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from TimeGAN.timegan import timegan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeGAN:\n",
    "    def __init__(self, seq_len, dim, hidden_dim, num_layers, gamma, beta):\n",
    "        self.seq_len = seq_len\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.rnn_cell = tf.keras.layers.LSTMCell(self.hidden_dim)\n",
    "        self.rnn = tf.keras.layers.RNN(self.rnn_cell, return_sequences=True)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.Input(shape=(self.seq_len, self.dim)))\n",
    "        model.add(tf.keras.layers.LSTM(self.hidden_dim, return_sequences=True))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.dim)))\n",
    "        return model\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.Input(shape=(self.seq_len, self.dim)))\n",
    "        model.add(tf.keras.layers.LSTM(self.hidden_dim, return_sequences=False))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "        return model\n",
    "    \n",
    "    def train(self, train_data, val_data, epochs=100, batch_size=64):\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        self.generator.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "        # Training process\n",
    "        for epoch in range(epochs):\n",
    "            # Add training steps here\n",
    "            pass\n",
    "    \n",
    "    def generate(self, n_samples):\n",
    "        random_data = np.random.rand(n_samples, self.seq_len, self.dim)\n",
    "        synthetic_data = self.generator.predict(random_data)\n",
    "        return synthetic_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "Original data shape: (700, 13)\n",
      "Synthetic data shape before reshaping: (1000, 30, 13)\n",
      "Synthetic data shape after flattening: (30000, 13)\n",
      "Synthetic data shape after inverse transformation and reshaping: (1000, 30, 13)\n",
      "Synthetic data saved to synthetic_data_timegan.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from TimeGAN.timegan import timegan # Assuming you have a TimeGAN implementation\n",
    "\n",
    "def clean_data(df):\n",
    "    # Convert all columns to numeric, forcing non-numeric values to NaN\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    # Fill NaN values with 0 or any other value as per your requirements\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "    train_data = pd.read_csv('training_set _labelled.csv')\n",
    "    val_data = pd.read_csv('validation_set _labelled.csv')\n",
    "    test_data = pd.read_csv('testing_set _labelled.csv')\n",
    "    \n",
    "    # Clean the data\n",
    "    train_data = clean_data(train_data)\n",
    "    val_data = clean_data(val_data)\n",
    "    test_data = clean_data(test_data)\n",
    "    \n",
    "    # Initialize scaler and fit on train_data\n",
    "    scaler = MinMaxScaler()\n",
    "    train_data_scaled = scaler.fit_transform(train_data.values)\n",
    "    val_data_scaled = scaler.transform(val_data.values)\n",
    "    \n",
    "    # Initialize TimeGAN\n",
    "    timegan_model = TimeGAN(seq_len=30, dim=train_data.shape[1], hidden_dim=24, num_layers=3, gamma=1, beta=1)\n",
    "    \n",
    "    # Train TimeGAN\n",
    "    timegan_model.train(train_data_scaled, val_data_scaled, epochs=100, batch_size=64)\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    synthetic_data = timegan_model.generate(n_samples=1000)\n",
    "    \n",
    "    # Handle NaN values\n",
    "    synthetic_data = np.nan_to_num(synthetic_data, nan=0)\n",
    "    \n",
    "    # Check the original data shape\n",
    "    original_data_shape = train_data.shape\n",
    "    print(\"Original data shape:\", original_data_shape)\n",
    "    \n",
    "    # Check the synthetic data shape before reshaping\n",
    "    print(\"Synthetic data shape before reshaping:\", synthetic_data.shape)\n",
    "    \n",
    "    # Assuming we need to match synthetic data to the original data's feature dimension\n",
    "    synthetic_data_flattened = synthetic_data.reshape(-1, synthetic_data.shape[-1])\n",
    "    print(\"Synthetic data shape after flattening:\", synthetic_data_flattened.shape)\n",
    "    \n",
    "    # Perform the inverse transformation\n",
    "    synthetic_data_scaled = scaler.inverse_transform(synthetic_data_flattened)\n",
    "    \n",
    "    # Optionally, reshape back to 3D shape if needed\n",
    "    synthetic_data_scaled_reshaped = synthetic_data_scaled.reshape(synthetic_data.shape)\n",
    "    print(\"Synthetic data shape after inverse transformation and reshaping:\", synthetic_data_scaled_reshaped.shape)\n",
    "    \n",
    "    # Save synthetic data to CSV\n",
    "    synthetic_data_df = pd.DataFrame(synthetic_data_scaled_reshaped.reshape(-1, synthetic_data.shape[-1]))\n",
    "    synthetic_data_df.to_csv('synthetic_data_timegan.csv', index=False)\n",
    "    print(\"Synthetic data saved to synthetic_data_timegan.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
